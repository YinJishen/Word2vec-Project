{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cnyin\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "C:\\Users\\cnyin\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as Data\n",
    "import string\n",
    "import mglearn\n",
    "\n",
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "sys.path.append(\"..\") \n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# novel \"the Hunger Games\"\n",
    "with open('the_hunger_games.txt', 'r') as f:\n",
    "    lines_hg = f.readlines()\n",
    "    \n",
    "# novel \"Catching Fire\"\n",
    "with open('catching_fire.txt', 'r') as g:\n",
    "    lines_cf = g.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = pd.read_csv('imdb_master2.csv')\n",
    "imdb_text = imdb['review'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_novel(lines):\n",
    "    import re\n",
    "    import string\n",
    "    txt = ''.join(lines)\n",
    "    sentences = [x for x in map(str.strip, re.split(',|\\.|\\n|\\?|;|!', txt)) if x]\n",
    "    pre_words = [x.translate(str.maketrans('', '', string.punctuation)).lower() for x in sentences]\n",
    "    \n",
    "    # only select sentences that have more than 3 words\n",
    "    words = list(filter(lambda x: len(x.split()) > 3, pre_words))\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb = clean_novel(imdb_text)[:50000]\n",
    "len(imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 27809)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(stop_words=\"english\", max_df=100)\n",
    "\n",
    "X = vect.fit_transform(imdb)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=10, learning_method=\"batch\",\n",
    "                               max_iter=25, random_state=0)\n",
    "\n",
    "document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 27809)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       topic 5       topic 6       topic 7       \n",
      "--------      --------      --------      --------      --------      --------      --------      --------      \n",
      "overall       type          drama         review        stories       talk          havent        whats         \n",
      "footage       dumb          child         fails         turns         definitely    gun           reviews       \n",
      "buy           unless        happens       cave          bother        rent          predictable   lots          \n",
      "cat           god           roles         van           plain         stay          enjoyed       taken         \n",
      "ride          unfortunately youve         box           check         sit           forced        pathetic      \n",
      "editing       sequel        die           voice         garbage       nearly        wait          chance        \n",
      "live          suspense      flat          ends          zombies       wasted        documentary   hardly        \n",
      "20            writer        gay           kept          barely        pointless     possibly      90            \n",
      "suppose       weak          trash         seriously     knows         expected      shoot         mr            \n",
      "imagine       fine          spoof         excuse        body          feels         bed           storyline     \n",
      "finish        opinion       late          holes         experience    gein          mentioned     excellent     \n",
      "jones         near          potential     happen        believable    soon          favorite      stand         \n",
      "ask           project       typical       hoping        sister        particularly  turkey        shame         \n",
      "similar       biggest       simple        quickly       comment       likes         personal      christian     \n",
      "chase         filmmakers    interested    perfect       giant         explain       values        pay           \n",
      "soundtrack    15            minute        disappointmentlaughable     werent        whatsoever    standard      \n",
      "credits       begin         shark         figure        points        redeeming     surprise      creepy        \n",
      "blame         rented        pure          laughing      problems      bought        effort        easy          \n",
      "meet          ended         falls         disappointing giving        ago           amusing       komodo        \n",
      "lee           twist         copy          average       killing       slasher       lighting      reading       \n",
      "\n",
      "\n",
      "topic 8       topic 9       \n",
      "--------      --------      \n",
      "hand          slow          \n",
      "badly         ok            \n",
      "hear          happened      \n",
      "finally       premise       \n",
      "actual        comments      \n",
      "viewers       words         \n",
      "level         sorry         \n",
      "hero          forward       \n",
      "strange       bored         \n",
      "miss          value         \n",
      "reality       okay          \n",
      "list          usually       \n",
      "romantic      sequences     \n",
      "telling       reasons       \n",
      "sandra        fast          \n",
      "flicks        note          \n",
      "jim           forget        \n",
      "wild          material      \n",
      "30            total         \n",
      "pass          released      \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mglearn.tools.print_topics(topics=range(10), feature_names=feature_names,\n",
    "                          sorting=sorting, topics_per_chunk=8, n_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
